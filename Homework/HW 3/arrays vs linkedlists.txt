doubly linked list - 0(1) time updates operations including insertions and deletions at arbitrary pisitions within the list

searchinng in chain is 0(n)


For the regional DB's, I would use a list, mainly because transactions are constantly added throughout the day as they occur.  Therefore, it would be very innefficient to constantly create a new array of greater size as each transaction occurs.  The alternative option, that is making a large array and only creating a new one when the original is full, is also not ideal as any leftover space in the array is wasted and copying into a new array would take time.  It would be best to use a list, which does not have a fixed size, and continuously add new transactions at the head of the list, or to keep a reference to the tail node and continuously add elements at the tail. (This would be done in O(1) time.)
Moreover, transactions are not regularly altered unless specifically requested and approved.  Therefore, due to the infrequency of such a task, it is not too problematic that carrying out this operation is less efficient in a list than in an array.  (In the list this would take O(n) time at worst.)  The same is true for retreiving information about transactions; though it may be more efficient in an array, the fact that this is not done as frequently as transactions are made, it is worth sacrificing the speed of information retreival in order to ensure efficient transaction completion.  (This would also take O(n) time.)  In addition, a doubly-linked list can be used to make these actions run faster.

For the corporate HQ, I would use an array.  Copying all of the regional linkedlists into the HQ array would take O(n) time.

It would be most ideal to use an array because insertions are not done on the HQ DB.  Combining multiple transactions from a single customer would be very easy in an array because there can be multiple dimensions in the array and a customer's transactions can all be moved into a single array at one index in the main array with the corresponding dimension containing the final sum.  If the managers want to search for transactions that will be at worst O(n) time, but if they already have the index of a transaction that is to be grouped with another transaction, relocating it will be O(1) time.  The indices of the customer's other transactions can then be set to null to effectively delete them(this would also take O(1) time).  The create a summary/roll-up by product, a multi-dimensional array can be placed in the last index of the main array which contains one dimension which gives the final dollar amount, with the other dimension at that location containing an array of all ID's to be retreived for that product line.  This would take O(n) time.
When meeting with the CEO, they can "drill into the details" at aggregate transactions by looking at the corresponding dimension containing the indices of the individual transactions.  They can also undo an aggregate by replacing the individual transaction bck at their original indices through their ID's.  This would take O(1) time.
The CEO can create a new summary/roll-up through the same method, combining items he sees fit into a single index and using multiple dimensions to maintain the indices of the individual components.  This would take O(n) time.